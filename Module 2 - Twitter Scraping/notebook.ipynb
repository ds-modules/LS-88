{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Visualization Module 2: Twitter Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter collects a *lot* of data. Ranging from tweets themselves, to data on users, to data on likes and other interactions, Twitter basically records everything that happens on their website. Lucky for data scientists like ourselves, Twitter also shares that data with us! In this assignment, we're going to use Twitter's Python API to analyze retweet statistics, demographics, and some other data too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other people are also interested in analyzing Twitter data, so there's been work done here already. That means other folks have developed useful collections of code ‚Äî called libraries ‚Äî which handle a lot of parsing and data management, so that we don't have to. Since these libraries are published online, we have access to all that hard work too! That means we can use code from those libraries to handle all the complicated Twitter models, so we only have to worry about the actual analysis (which is the fun part)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't need to worry too much about the code in the next cell. It's purpose is to import libraries that other people have written, so that we have access to them later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-3.5.0-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.4.1 (from tweepy)\n",
      "  Using cached requests_oauthlib-0.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.4.3 in /usr/local/lib/python2.7/site-packages (from tweepy)\n",
      "Requirement already satisfied: six>=1.7.3 in /usr/local/Cellar/matplotlib/2.0.2/libexec/lib/python2.7/site-packages (from tweepy)\n",
      "Collecting oauthlib>=0.6.2 (from requests-oauthlib>=0.4.1->tweepy)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-2.0.2 requests-oauthlib-0.8.0 tweepy-3.5.0\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.13.0-py2.py3-none-any.whl (631kB)\n",
      "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 634kB 1.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting nltk>=3.1 (from textblob)\n",
      "  Downloading nltk-3.2.4.tar.gz (1.2MB)\n",
      "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2MB 865kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/Cellar/matplotlib/2.0.2/libexec/lib/python2.7/site-packages (from nltk>=3.1->textblob)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sequoia/Library/Caches/pip/wheels/79/8b/2a/b2da7fce57a1fd9b20b08fa8800c83b6fde62af9e880722e29\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk, textblob\n",
      "Successfully installed nltk-3.2.4 textblob-0.13.0\n",
      "Collecting plotly\n",
      "  Downloading plotly-2.0.15.tar.gz (1.0MB)\n",
      "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.0MB 978kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.0.6 in /usr/local/lib/python2.7/site-packages (from plotly)\n",
      "Collecting nbformat>=4.2 (from plotly)\n",
      "  Downloading nbformat-4.4.0-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163kB 4.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /usr/local/Cellar/matplotlib/2.0.2/libexec/lib/python2.7/site-packages (from plotly)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python2.7/site-packages (from plotly)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/matplotlib/2.0.2/libexec/lib/python2.7/site-packages (from plotly)\n",
      "Collecting jsonschema!=2.5.0,>=2.4 (from nbformat>=4.2->plotly)\n",
      "  Downloading jsonschema-2.6.0-py2.py3-none-any.whl\n",
      "Collecting ipython-genutils (from nbformat>=4.2->plotly)\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl\n",
      "Collecting traitlets>=4.1 (from nbformat>=4.2->plotly)\n",
      "  Downloading traitlets-4.3.2-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81kB 7.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-core (from nbformat>=4.2->plotly)\n",
      "  Downloading jupyter_core-4.3.0-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81kB 6.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: functools32; python_version == \"2.7\" in /usr/local/Cellar/matplotlib/2.0.2/libexec/lib/python2.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2->plotly)\n",
      "Collecting enum34; python_version == \"2.7\" (from traitlets>=4.1->nbformat>=4.2->plotly)\n",
      "  Using cached enum34-1.1.6-py2-none-any.whl\n",
      "Building wheels for collected packages: plotly\n",
      "  Running setup.py bdist_wheel for plotly ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sequoia/Library/Caches/pip/wheels/c9/c4/00/a80b040dd8c9301d29f7153881c96edf1cd8561977ec440941\n",
      "Successfully built plotly\n",
      "Installing collected packages: jsonschema, ipython-genutils, enum34, traitlets, jupyter-core, nbformat, plotly\n",
      "Successfully installed enum34-1.1.6 ipython-genutils-0.2.0 jsonschema-2.6.0 jupyter-core-4.3.0 nbformat-4.4.0 plotly-2.0.15 traitlets-4.3.2\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python2.7/site-packages\n",
      "Requirement already satisfied: six in /usr/local/Cellar/matplotlib/2.0.2/libexec/lib/python2.7/site-packages (from nltk)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy    # This lets us access Twitter data.\n",
    "!pip install textblob  # This will help us parse text.\n",
    "!pip install plotly    # This makes it easy to plot graphs.\n",
    "!pip install nltk      # This is also to parse text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work on Twitter data, we'll first need two things: a Twitter account, and Twitter keys. Here are the steps to follow:\n",
    "\n",
    "1. [Create a Twitter account](https://twitter.com).  You can use an existing account if you have one.\n",
    "1. [Create a Twitter developer account](https://dev.twitter.com/resources/signup).  Attach it to your Twitter account.\n",
    "1. Once you're logged into your developer account, [create an application for this assignment](https://apps.twitter.com/app/new).  You can call it whatever you want, and you can write any URL when it asks for a web site.\n",
    "1. On the page for that application, find your Consumer Key and Consumer Secret. Don't lose these!\n",
    "1. On the same page, create an Access Token. Record the resulting Access Token and Access Token Secret. Don't lose these either!\n",
    "\n",
    "**Security concern: Do not share your access keys with anyone. They can be used to manage your Twitter account without your permission.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your credentials in the cell below. Your program will use them to access Twitter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_key = \"\"\n",
    "access_secret = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will authorize your program to request Twitter data, through the developer account you just set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: A lot of data scientists like Twitter data. As a result, you can only request data approximately once every 15 minutes to keep Twitter's servers from crashing due to too much activity. Use your requests wisely to avoid unnecessary waiting time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that everything is set up, we can use [Twitter's search API](https://dev.twitter.com/rest/reference/get/search/tweets) to find the word \"Berkeley\". This will give us the same results as using [Twitter's online \"search\" page](https://twitter.com/search?q=berkeley)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweepy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8ee9b6ba6266>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results = tweepy.Cursor(api.search,   # `api.search` specifies we want to perform a search.\n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Berkeley'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# `q` is the query, or the words we're searching for.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         result_type='recent') # We'll prioritize more recent results first.\n\u001b[1;32m      4\u001b[0m \u001b[0mfirst_ten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Now `first_ten` is just the first 10 tweets we get.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweepy' is not defined"
     ]
    }
   ],
   "source": [
    "results = tweepy.Cursor(api.search,   # `api.search` specifies we want to perform a search.\n",
    "                        q='Berkeley', # `q` is the query, or the words we're searching for.\n",
    "                        result_type='recent') # We'll prioritize more recent results first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `results` is a long list of search results. Since it is actually pretty extensive, let's just take the first ten results. In the next cell we build up a list called `first_ten`, which contains just the first ten tweets we found in `results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-64183f94ce8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfirst_ten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m                  \u001b[0;31m# We start out with an empty list called `first_ten`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Then, we'll iterate over the first 10 tweets in `results`...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfirst_ten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# And we'll add each of those tweets to `first_ten`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "first_ten = []                  # We start out with an empty list called `first_ten`.\n",
    "for tweet in results.items(10): # Then, we'll iterate over the first 10 tweets in `results`...\n",
    "    first_ten.append(tweet)     # And we'll add each of those tweets to `first_ten`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets have a peek at what the data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(first_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploring the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter gives us a lot of information about each tweet, not just its text. You can read about all the details [here](https://dev.twitter.com/overview/api/tweets). Let's look at one tweet to get a sense of the information we have available. We can access just the first tweet in our list by indexing into it. Note, the first index in the list is actually 0, not 1, so we will actually say `first_ten[0]` to see the first tweet in our list of ten tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7feba532fbdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_ten\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Try changing this to any number 0-9, to see other tweets in the list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(first_ten[0]) # Try changing this to any number 0-9, to see other tweets in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "Which field contains each of the following attributes:\n",
    "1. The tweet's text?\n",
    "1. The time when the tweet was posted?\n",
    "1. The geographic location of the tweet?\n",
    "1. The source (device and app) where the tweet was written?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "1. \n",
    "1. \n",
    "1. \n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyzing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to do analysis! Let's start out by getting a list, where each entry corresponds to how many retweets we got in the first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4543, 0, 1, 3214, 1054, 15, 1, 34, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "retweet_counts = []                      # We start with an empty list called `retweet_counts`.\n",
    "for tweet in first_ten:                  # Then, we iterate over the tweets in `first_ten`...\n",
    "    retweet_count = tweet.retweet_count  # And, for each tweet, get the number of retweets...\n",
    "    retweet_counts.append(retweet_count) # And append that number to our list `retweet_counts`.\n",
    "    \n",
    "print(retweet_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and draw it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP3MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b925b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(retweet_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter search api provides three modes (check out this guide) for the result_type: mix, recent, and popular. In the previous code, we retrieved the popular tweets. \n",
    "Now it is your turn to retrieve recent 100 tweets and assign them to a new variable (e.g., results_recent100), then plot a histogram for the retweet count of the recent 100 tweets. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 \n",
    "Compare and contrast between the two histograms for retweet counts of recent and popular 100 tweets that returns from searching the word Berkeley. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.\n",
    "Twitter search api has an option to limit the search by geo location. The parameter value is specified by ‚Äùlatitude,longitude,radius‚Äù. Compare the top 10 popular tweets text from four geo locations: Berkeley, Kansas City, New York, and Barcelona Spain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User handles\n",
    "Instead of searching for tweets, you can use Twitter APIs to get details about specific user account. It includes user‚Äôs timeline, followers, etc.\n",
    "\n",
    "Get the latest 10 tweets from an account that interests you (e.g.,  UCBerkeley) twitter account using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle_results = api.user_timeline(screen_name='UCBerkeley', count=10)\n",
    "\n",
    "handle_results_tweets = []\n",
    "\n",
    "for t in handle_results:\n",
    "    handle_results_tweets.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-Sep-01 03:02\n",
      "NEXT WEEK: 50 years of protest photos to open @ucbsoj https://t.co/A6pvEsWERd j https://t.co/GQzQ4Ptybf\n",
      "\n",
      "2017-Sep-01 02:07\n",
      "Distant galaxy sends out 15 high-energy radio bursts https://t.co/v01bqRNumR https://t.co/BY99a6IDk9\n",
      "\n",
      "2017-Sep-01 01:03\n",
      "BLOG: On sexism in economics https://t.co/AlzpF6SqWT https://t.co/SjwTRyZRGb\n",
      "\n",
      "2017-Aug-31 23:54\n",
      "RT @berkeleyforum: Join us tonight at 6:00 PM in 112 Wurster as The Berkeley Forum hosts new Chancellor Carol Christ. https://t.co/ZTYYHAVM‚Ä¶\n",
      "\n",
      "2017-Aug-31 22:04\n",
      "BLOG: Working outside the #tech bubble https://t.co/8jgkESKfuD #startup https://t.co/51jJkuoh27\n",
      "\n",
      "2017-Aug-31 19:02\n",
      "BLOG: #Houston, we all have a problem https://t.co/bd3ODC2oQT #Harvey https://t.co/YVpuXhr9mQ\n",
      "\n",
      "2017-Aug-31 17:02\n",
      "FRIDAY: Campus memorial Friday for chief counsel Chris Patti https://t.co/TGNfellJUg https://t.co/DxYQEeAGt5\n",
      "\n",
      "2017-Aug-31 16:04\n",
      "Girls‚Äô #STEM camp connects with campus https://t.co/b2UrYFdleK #girlsinstem https://t.co/VJQO9Omlwd\n",
      "\n",
      "2017-Aug-31 07:04\n",
      "More than a decade in the works, Chou Hall is now open to students ‚Äî it may be the #green-est ever!‚Ä¶ https://t.co/AraUVYdris\n",
      "\n",
      "2017-Aug-31 03:02\n",
      "STUDENTS:  üëÄ for a class to add? @BerkeleyGuide lists open, high-interest, undergrad classes rec'd by depts &amp; faculty #checkitout\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print the test of the first 10 tweets\n",
    "for t in handle_results_tweets:\n",
    "    print(t.created_at.strftime(\"%Y-%b-%d %H:%M\"))\n",
    "    print(t.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "Look at the text of retrieved tweets and compare them to the latest 10 tweets of the [web interface](https://twitter.com/UCBerkeley) for the same user. Do you see any difference? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of a followers for UCBerkeley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-9b38d1c4c3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfollowers_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfollowers_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfollowers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UCBerkeley'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandle_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mfollowers_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "followers_list = []\n",
    "\n",
    "followers_results = api.followers(screen_name='UCBerkeley', count=200, page=i)\n",
    "for f in handle_results:\n",
    "      followers_list.append(f)\n",
    "\n",
    "for f in followers_list:\n",
    "    print(f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There‚Äôs a limit on how many users can be returned by one request. If you need more, please read [using cursors to navigate collections](https://dev.twitter.com/overview/api/cursoring)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus Question\n",
    "Based on profile_location in the follower data, draw a map for both followers lists for Donald Trump and Hillary Clinton. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting the assignment\n",
    "\n",
    "- Delete your Twitter API credentials, ie. re-assign `consumer_key`, `consumer_secret`, `access_key`, and `access_secret` to empty strings so that we won't see your credentials when you save and sumbit it.\n",
    "- Save this jupyter notebook as a pdf. Click File, Download as, PDF via LaTex (.pdf).\n",
    "- Upload the pdf file into bcourses under Assignment 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
